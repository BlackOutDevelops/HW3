{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Homework_03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XaIWT",
      "launcher_item_id": "zAgPl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzo37yE6ejuA"
      },
      "source": [
        "# Convolution Neural Network Homework\n",
        "\n",
        "This is the 3rd assignment for CAP 4630 and we will go through some primary operations for image processsing and implement one of the earilest representative convolution neural network - LeNet-5 . \\\n",
        "You will use **\"Tasks\"** and **\"Hints\"** to finish the work. **(Total 100 Points)** \\\n",
        "For section 1, when you implement covolution and maxpooling, you are **not** allowed to use built-in functions in Machine Learning libaries such as Scikit-learn Keras, Tensorflow, Pytorch; but you are encouraged to employ Keras for second section.\n",
        "\n",
        "**Task Overview:**\n",
        "- Basic operations for Digital Image Processing (DIP)\n",
        "- LeNet-5 (Google Colab is recommended for implementation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLKjpQvaejuF"
      },
      "source": [
        "## 1 - Basic Image Processing ##\n",
        "### 1.1 Data Preparation \n",
        "\n",
        "Import useful packages and prepare image data as an array for image processing. **(5 Points)**\n",
        "\n",
        "**Tasks:**\n",
        "1. Import numpy and rename it to np.\n",
        "2. Import imageio and call imread to convert image to an array.\n",
        "3. **DISPLAY** the image in the output box before image-array conversion.\n",
        "4. **PRINT OUT** the size of the array\n",
        "5. **PRINT OUT** the numeric matrix form of image, i.e. the obtained array after image-array conversion.\n",
        "\n",
        "References:\n",
        "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
        "- [imageio](https://imageio.github.io/) is a python library for basic image reading and writing.\n",
        "\n",
        "**Hints:**\n",
        "1. Image data is under current directory, i.e., \"./image.jpg\".\n",
        "2. You may consider importing \"display\" and \"Image\" from IPython.display for image display."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvITLRocejuG"
      },
      "source": [
        "# Import useful libraries\n",
        "import numpy as np\n",
        "import imageio\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Display original image\n",
        "\n",
        "\n",
        "# # Convert image to array, print out the shape of array, and print out the entire array\n",
        "# img_matrix = ...\n",
        "# print(img_matrix.shape)\n",
        "# print(img_matrix)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY5djq-tejuI"
      },
      "source": [
        "### 1.2 Implementation of Convolution Filter\n",
        "\n",
        "Process the obtained array from the image with convolution operation. **(20 Points)**\n",
        "\n",
        "**Tasks:**\n",
        "1. Prepare a 3X3 Laplacian kernel (aka Laplacial filter) with array as convolution filter.\n",
        "2. Conduct convolution on image with prepared kernel.\n",
        "3. **PRINT OUT** convolution result for first ten rows.\n",
        "4. **PRINT OUT** the shape of the convolution result.\n",
        "5. **DISPLAY** convolution result as image with matplotlib. (Don't worry about the value <0 or >255. Scaling process will be conducted in imshow function to make sure valid display.)\n",
        "\n",
        "\n",
        "**Hints:**\n",
        "1. Laplacian kernel is widely used for edge detection. Its form is shown below:\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=15bP8KCwHLtglJ-WXV4wolm4m46mCp3HL)\n",
        "\n",
        "2. You may consider the following steps for this implementation.\\\n",
        "    2.1 Extract all centriods of processing region for each convolution operation.\\\n",
        "    2.2 According to each centroid, locate all indices of the elements within the local region for each convolution operation.\\\n",
        "    2.3 Given obtained indices, locate pixel values (i.e. our obtained array elements) and conduct element-wise product between pixel and kernel values.\\\n",
        "    2.4 Sum element-wise product results and assign the value to convolution result at corresponding location.\\\n",
        "    **Note: we did not conduct padding for processed array, and thus, convolution result will become smaller than original array. You may think about the reason.**\n",
        "3. Validation for first 5X5 array (from upper-left corner), i.e., filtered_results[0:5,0:5]. The example figure is below.\n",
        "\n",
        "[[ 134.   37.   98.  195.  173.]\\\n",
        " [ -75.  -80.   56.  -65.  182.]\\\n",
        " [  96.  -37. -163.   22.   68.]\\\n",
        " [-101.  121.   81.  148.  -71.]\\\n",
        " [   7.  127. -141.  159. -127.]]\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=18Iis1mJsvEaojZ7O3f3soE152Szwy8_Z)\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnc8BNW9ejuJ"
      },
      "source": [
        "######## Convolution with Laplacian Filter ##################\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMN_XE1xejuJ"
      },
      "source": [
        "### 1.3 Modification on Convolution Scheme\n",
        "\n",
        "Conduct the convolution with the same filter as above, but change the stride to 2. **(5 Points)**\n",
        "\n",
        "**Tasks:**\n",
        "1. Modify the convolution process with stride=2\n",
        "2. **PRINT OUT** convolution result for first ten rows.\n",
        "3. **PRINT OUT** the shape of the convolution result.\n",
        "4. **DISPLAY** convolution result as image with matplotlib.(Don't worry about the value <0 or >255. Scaling process will be conducted in imshow function to make sure valid display.)\n",
        "\n",
        "**Hints:**\n",
        "1. You may just reduce the centroid pool according to stride=2, and then, follow the same convolution process above.\n",
        "    **Note: After increase of stride, the size of convolution result is further shrinked. You may think about the reason.**\n",
        "2. Validation for first 5X5 array (from upper-left corner), i.e., filtered_results[0:5,0:5]. The example figure is below.\n",
        "\n",
        "[[ 134.   98.  173.    5.    3.]\\\n",
        " [  96. -163.   68.  -10.   37.]\\\n",
        " [   7. -141. -127.  142.   -6.]\\\n",
        " [  -1.  -46.  109.  -13.   11.]\\\n",
        " [ 106.   49.  241.  -26.  -33.]]\n",
        " \n",
        " \n",
        "![](https://drive.google.com/uc?export=view&id=1UPdXt5cY1umImu2chaQLfWAnqDEpFOGV)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyFLwZxYejuJ"
      },
      "source": [
        "######## Convolution with Laplacian Filter and the setting of stride=2 ##################\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2PT6NpSejuL"
      },
      "source": [
        "### 1.4 Implementation of MaxPooling\n",
        "\n",
        "Process the obtained array from the image with MaxPooling operation. **(15 Points)**\n",
        "\n",
        "**Tasks:**\n",
        "1. Prepare a 2X2 pooling mask.\n",
        "2. Conduct max pooing on image with prepared mask.\n",
        "3. **PRINT OUT** convolution result for first ten rows.\n",
        "4. **PRINT OUT** the shape of the convolution result.\n",
        "5. **DISPLAY** convolution result as image with matplotlib.(Don't worry about the value <0 or >255. Scaling process will be conducted in imshow function to make sure valid display.)\n",
        "\n",
        "**Hints:**\n",
        "1. You may just modify the centroid pool to top-left corner pool, and then, follow the same strategy above.\\\n",
        "    **Note: After the pooling, the size of the array is shrinked. You may think about the reason.**\n",
        "2. Validation for first 5X5 array (from upper-left corner), i.e., pooled_results[0:5,0:5].The example figure is below.\n",
        "\n",
        "[[ 98. 112.  93. 195. 173.]\\\n",
        " [ 84. 127. 137. 253. 254.]\\\n",
        " [ 85. 145. 225. 255. 242.]\\\n",
        " [104. 178. 216. 230. 242.]\\\n",
        " [ 95. 186. 147. 248. 242.]]\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1a18IWjrN0xHcp7bSNuj8kUM4JFFj3ebd)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOV72Sp9ejuL"
      },
      "source": [
        "######## MaxPooling with the setting of 2X2 ##################\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCxlJYlqejuM"
      },
      "source": [
        "## 2 - Convolution Neural Network ##\n",
        " \n",
        "In this section, we will use LeNet-5 (LeCun et al., 1998), one of representative deep nueral networks, to solve a  classification problem with Fashion MNIST benchmark.\n",
        "\n",
        "### 2.1 Library Preparation\n",
        "\n",
        "Import useful deep learning packages. \n",
        "\n",
        "**Tasks:**\n",
        "1. Import numpy and rename it to np.\n",
        "2. Import keras from tensorflow.\n",
        "3. Import layers from tensorflow.keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5enuEKHejuM"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUs3cBXXejuN"
      },
      "source": [
        "### 2.2 Training Data Preparation\n",
        "\n",
        "Import useful packages and prepare Fashion MNIST data. **(20 Points)**\n",
        "\n",
        "**Tasks:**\n",
        "1. Download Fashion MNIST data and split it with keras and prepare training/test data sets.\n",
        "2. Preprocess training/test data with normalization, dimension extension, and zero padding (for LeNet-5 configuration).\n",
        "3. Preprocess label data to binary class matrices.\n",
        "4. **PRINT OUT** first image in training set and its correponding label index\n",
        "5. **PRINT OUT** the shape of total training data, the number of training samples, and the number of test samples.\n",
        "\n",
        "**Hints**\n",
        "1. You may consider load function from the reference link. https://keras.io/api/datasets/ It provides dataloader function which can tackle downloading and data splitting automatically.\n",
        "2. For label preprocessing, you may consider **keras.utils.to_categorical** to convert class vectors to binary class matrices. This conversion makes sure the label can match the format of prediction output from neural network.\n",
        "3. For image display, consider showing the image and label **before dimension expansion and label preprocessing**.\n",
        "4. You may consider MNIST processing shown in class as an example.\n",
        "\n",
        "**References**\n",
        "- Fashion MNIST https://github.com/zalandoresearch/fashion-mnist\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjyfYiGrejuN"
      },
      "source": [
        "# # the data, split between train and test sets with keras.datasets\n",
        "\n",
        "# Model / data parameters\n",
        "# num_classes = ...\n",
        "# input_shape = (32, 32, 1) ## think about the reason\n",
        "\n",
        "# # Image Normalization (Scaling to [0, 1])\n",
        "# x_train = ... \n",
        "# x_test = ... \n",
        "\n",
        "# Print out first image and its correponding label index\n",
        "\n",
        "# # Dimension expansion to ensure that images have shape (28, 28, 1)\n",
        "# x_train = ...\n",
        "# x_test = ...\n",
        "\n",
        "# # Conduct padding on training/test images to (32, 32, 1) for LeNet-5\n",
        "# x_train = np.pad(x_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "# x_test = np.pad(x_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "\n",
        "# # Print out the training/test data shapes and the numbers of training/test samples\n",
        "# print(\"x_train shape:\", x_train.shape)\n",
        "# print(x_train.shape[0], \"train samples\")\n",
        "# print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# # convert label vectors to binary class matrices for training/test labels \n",
        "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "# y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw4GqzZmejuN"
      },
      "source": [
        "### 2.3 LeNet-5 \n",
        "\n",
        "Construct LeNet-5 as learning model for Fashion MNIST classification task. **(15 Points)**\n",
        "\n",
        "**Tasks:**\n",
        "1. Build up LeNet-5 with keras.Sequential\n",
        "2. Set the regularizer to l2 and regularizer lambda is **4e-5**.\n",
        "2. **PRINT OUT** the model summary.\n",
        "\n",
        "**Hints:**\n",
        "1. You may consider the convolution neural network shown in class as an example.\n",
        "2. The structure of LeNet-5 is listed below. Try to map each step to related processing operation. You can also search some materials to faciliate implementation. \n",
        "3. Some architecture settings are listed below. \n",
        "    - The kernel size for 2D convolution filter is **5 X 5**. You may think about the reason by calculation.\n",
        "    - Regularizer is set to L2 regularizer with **kernel_regularizer=regularizers.l2(4e-5)**.\n",
        "    - We change tanh activation to **\"relu\"** activation here. Please use **activation=\"relu\"** for implementation.\n",
        "    - We use MaxPooling instead of original AveragePooling. Please use \"**MaxPooling2D(pool_size=(2, 2))**\" for implementation.\n",
        "    - Please use **Flatten** to onvert 2D convolution layer to 1D fully connected layer.\n",
        "    - Gaussian connections are replaced with Softmax, and thus, the outputs are activated by Softmax function based on the number of classes.\n",
        "\n",
        "4. Validation result:\n",
        "    - Total params: 61,706\n",
        "    - Trainable params: 61,706\n",
        "    - Non-trainable params: 0\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1Ks9RasENa0KiYRi2vwfJ_BQxkLB-x49R)\n",
        "\n",
        "\n",
        "**References:**\n",
        "- http://yann.lecun.com/exdb/lenet/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c97heiiSejuN"
      },
      "source": [
        "### Construct LeNet-5\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# model = keras.Sequential(\n",
        "#     [\n",
        "#         keras.Input(shape=input_shape),\n",
        "#         layers.Conv2D(..., kernel_size=(...), kernel_regularizer=..., activation=...), #C1\n",
        "#         layers.MaxPooling2D(pool_size=(...)), # S2 Subsampling\n",
        "#         layers.Conv2D(..., kernel_size=(...), kernel_regularizer=..., activation=...), # C3\n",
        "#         layers.MaxPooling2D(pool_size=(...)), # S4 Subsampling\n",
        "#         layers.Flatten(), # Convert 2D convolution layer to 1D fully connected layer\n",
        "#         layers.Dense(..., kernel_regularizer=..., activation = ...), # C5\n",
        "#         layers.Dense(..., kernel_regularizer=..., activation = ...), # F6\n",
        "#         layers.Dense(num_classes, activation=...), # OUTPUT\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmVzUU9oejuO"
      },
      "source": [
        "#### 2.4 LeNet-5 Model Training\n",
        "\n",
        "Train LeNet-5 model with specific training strategy. **(20 Points)**\n",
        "\n",
        "**Tasks:**\n",
        "1. Set batch size to **64** for training. \n",
        "2. Pick **SGD optimizer** with learning rate of **0.1**, momentum of **0.9**, and **nesterov=True**, for model training.\n",
        "3. Pick **cross-entropy** loss function for optimization and evaluation metrics is set to **accuracy**.\n",
        "4. Set validation_split to **0.1** which means it excludes 1/10 training data for validation process.\n",
        "4. Train the model with **10 epochs**.\n",
        "5. Evaluate model with test data set and **PRINT OUT** : **test loss** and **test accuracy**. Note that the model here is the **LAST** model after **10 epochs** training.\n",
        "\n",
        "**Hints:**\n",
        "1. You may consider the examples from Keras to specify optimizer parameters. https://keras.io/api/optimizers/\n",
        "2. You may use the example shown in class to faciliate this implementation.\n",
        "3. You may see slightly different results every time you run the training. It is normal since there is randomness for training. However, you should expect the **BEST** validation accuracy is above **87%** which may not be the result from last epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz-Cvsu8ejuO"
      },
      "source": [
        "### Train with SGD optimizer with learning rate =0.1, regularizer=4e-5, momentum=0.9, and nesterov=True\n",
        "\n",
        "# batch_size = ...\n",
        "# epochs = ...\n",
        "# sgd = keras.optimizers.SGD(lr=..., momentum=..., nesterov=...)\n",
        "# model.compile(loss=..., optimizer=..., metrics=[...])\n",
        "# history = model.fit(..., ..., batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi-xsLUiejuO"
      },
      "source": [
        "### Print out the evaluation results, including test loss and test accuracy.\n",
        "\n",
        "# score = model.evaluate(..., ..., verbose=0)\n",
        "# print(\"Test loss:\", score[0])\n",
        "# print(\"Test accuracy:\", score[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}